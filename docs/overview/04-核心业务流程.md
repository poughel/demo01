# DataSophon 核心业务流程分析

## 一、集群创建流程

### 1.1 流程概述

集群创建是 DataSophon 的核心功能之一，涉及多个模块的协作。

### 1.2 详细流程图

```
用户 (Web UI)
    ↓ 1. 填写集群信息
ClusterInfoController.save()
    ↓ 2. 保存集群基本信息
ClusterInfoService.saveCluster()
    ↓ 3. 验证集群名称唯一性
    ↓ 4. 创建集群记录
ClusterInfoMapper.insert()
    ↓ 5. 返回集群 ID
    ↓ 6. 初始化集群配置
    ↓ 7. 创建默认告警组
    ↓ 8. 返回成功结果
用户 (Web UI)
    ↓ 显示集群列表
```

### 1.3 关键步骤详解

#### 步骤1: 用户输入集群信息
```json
{
  "clusterName": "production-cluster",
  "clusterCode": "prod-001",
  "clusterFrame": "DDP-1.2.2",
  "frameVersion": "1.2.2"
}
```

#### 步骤2: Controller 层处理
```java
@RequestMapping("/save")
@UserPermission
public Result save(@RequestBody ClusterInfoEntity clusterInfo) {
    // 参数验证
    if (StringUtils.isBlank(clusterInfo.getClusterName())) {
        return Result.error("集群名称不能为空");
    }
    
    // 调用 Service 层
    return clusterInfoService.saveCluster(clusterInfo);
}
```

#### 步骤3-4: Service 层业务逻辑
```java
public Result saveCluster(ClusterInfoEntity clusterInfo) {
    // 1. 检查集群名称是否已存在
    ClusterInfoEntity exists = clusterInfoMapper.selectByClusterName(
        clusterInfo.getClusterName()
    );
    if (exists != null) {
        return Result.error("集群名称已存在");
    }
    
    // 2. 设置默认值
    clusterInfo.setClusterState(ClusterState.NEED_CONFIG);
    clusterInfo.setCreateTime(new Date());
    
    // 3. 插入数据库
    clusterInfoMapper.insert(clusterInfo);
    
    // 4. 初始化集群配置
    initClusterConfig(clusterInfo.getId());
    
    // 5. 创建默认告警组
    createDefaultAlertGroup(clusterInfo.getId());
    
    return Result.success().put("clusterId", clusterInfo.getId());
}
```

## 二、主机添加流程

### 2.1 流程图

```
用户 (Web UI)
    ↓ 1. 输入主机列表
HostInstallController.install()
    ↓ 2. 验证主机连接性
    ├─ SSH 连接测试
    ├─ 权限检查
    └─ 环境检查
    ↓ 3. 批量添加主机
ClusterHostService.batchAddHost()
    ↓ 4. 保存主机信息
    ↓ 5. 下发 Worker 安装任务
DispatcherWorkerActor
    ↓ 6. 发送安装命令
Worker 节点
    ↓ 7. 安装 Worker 服务
    ↓ 8. 启动 Worker
    ↓ 9. 向 Master 注册
Master
    ↓ 10. 更新主机状态
    ↓ 11. 通知前端
Web UI
    ↓ 显示主机列表
```

### 2.2 SSH 连接测试

```java
public CheckResult checkSshConnection(HostInfo hostInfo) {
    try {
        // 创建 SSH 会话
        Session session = createSshSession(
            hostInfo.getIp(),
            hostInfo.getSshPort(),
            hostInfo.getSshUser(),
            hostInfo.getSshPassword()
        );
        
        // 连接测试
        session.connect(5000); // 5秒超时
        
        // 执行测试命令
        ExecResult result = execSshCommand(session, "whoami");
        
        session.disconnect();
        
        if (result.isSuccess()) {
            return CheckResult.success("SSH 连接成功");
        } else {
            return CheckResult.failed("命令执行失败");
        }
    } catch (Exception e) {
        return CheckResult.failed("SSH 连接失败: " + e.getMessage());
    }
}
```

### 2.3 Worker 安装脚本

```bash
#!/bin/bash
# install-worker.sh

WORKER_HOME=/opt/datasophon/worker
MASTER_HOST=$1

# 1. 创建目录
mkdir -p $WORKER_HOME
cd $WORKER_HOME

# 2. 下载 Worker 安装包
wget http://${MASTER_HOST}:8081/packages/datasophon-worker.tar.gz

# 3. 解压
tar -zxvf datasophon-worker.tar.gz

# 4. 配置
cat > conf/application.yml <<EOF
masterHost: ${MASTER_HOST}
workerPort: 2552
EOF

# 5. 启动 Worker
./bin/start-worker.sh

# 6. 检查启动状态
sleep 5
if ps -ef | grep -v grep | grep datasophon-worker; then
    echo "Worker started successfully"
else
    echo "Worker start failed"
    exit 1
fi
```

## 三、服务安装流程

### 3.1 流程图

```
用户 (Web UI)
    ↓ 1. 选择服务和主机
ServiceInstallController.install()
    ↓ 2. 解析服务依赖
    ↓ 3. 构建 DAG 图
DAGBuildActor
    ↓ 4. 拓扑排序
    ↓ 5. 生成任务列表
    ↓ 6. 按依赖顺序执行
ClusterActor
    ↓ 7. 分发安装任务
DispatcherWorkerActor
    ↓ 8. 发送到 Worker
Worker (InstallServiceHandler)
    ├─ 9. 下载安装包
    ├─ 10. 解压安装包
    ├─ 11. 生成配置文件
    ├─ 12. 设置权限
    └─ 13. 创建目录
    ↓ 14. 返回结果
ServiceExecuteResultActor
    ↓ 15. 收集结果
    ↓ 16. 更新服务状态
    ↓ 17. 通知前端
Web UI
    ↓ 显示安装进度
```

### 3.2 服务依赖解析

```java
public class ServiceDependencyResolver {
    
    public DAG<String, ServiceInfo, String> buildDependencyDAG(
            List<ServiceInfo> services) {
        DAG<String, ServiceInfo, String> dag = new DAG<>();
        
        // 1. 添加所有服务节点
        for (ServiceInfo service : services) {
            dag.addNode(service.getName(), service);
        }
        
        // 2. 添加依赖关系（边）
        for (ServiceInfo service : services) {
            List<String> dependencies = service.getDependencies();
            if (dependencies != null) {
                for (String dependency : dependencies) {
                    // dependency -> service (dependency 必须先于 service 安装)
                    dag.addEdge(dependency, service.getName());
                }
            }
        }
        
        return dag;
    }
}
```

**示例: Hadoop 生态组件依赖关系**
```
ZooKeeper (无依赖)
    ↓
HDFS (依赖 ZooKeeper)
    ↓
YARN (依赖 HDFS)
    ↓
Hive (依赖 HDFS + YARN)
    ↓
Spark (依赖 HDFS + YARN)
```

### 3.3 DAG 拓扑排序

```java
public List<String> topologicalSort(DAG<String, ServiceInfo, String> dag) {
    List<String> result = new ArrayList<>();
    Set<String> visited = new HashSet<>();
    Map<String, Integer> inDegree = calculateInDegree(dag);
    
    // 1. 找出入度为 0 的节点（无依赖）
    Queue<String> queue = new LinkedList<>();
    for (Map.Entry<String, Integer> entry : inDegree.entrySet()) {
        if (entry.getValue() == 0) {
            queue.offer(entry.getKey());
        }
    }
    
    // 2. BFS 遍历
    while (!queue.isEmpty()) {
        String node = queue.poll();
        result.add(node);
        visited.add(node);
        
        // 3. 更新后继节点的入度
        Set<String> successors = dag.getSubsequentNodes(node);
        for (String successor : successors) {
            inDegree.put(successor, inDegree.get(successor) - 1);
            if (inDegree.get(successor) == 0) {
                queue.offer(successor);
            }
        }
    }
    
    // 4. 检查是否有环
    if (result.size() != dag.getNodesCount()) {
        throw new RuntimeException("Circular dependency detected");
    }
    
    return result;
}
```

### 3.4 并行安装优化

```java
public void parallelInstall(List<ServiceInfo> services) {
    DAG<String, ServiceInfo, String> dag = buildDependencyDAG(services);
    List<String> sortedServices = topologicalSort(dag);
    
    ExecutorService executor = Executors.newFixedThreadPool(10);
    Map<String, Future<ExecuteResult>> futures = new HashMap<>();
    Set<String> completed = new HashSet<>();
    
    for (String serviceName : sortedServices) {
        // 等待依赖服务完成
        ServiceInfo service = dag.getNodeInfo(serviceName);
        waitForDependencies(service.getDependencies(), futures, completed);
        
        // 并行安装当前服务
        Future<ExecuteResult> future = executor.submit(() -> {
            return installService(serviceName);
        });
        futures.put(serviceName, future);
    }
    
    executor.shutdown();
    executor.awaitTermination(1, TimeUnit.HOURS);
}
```

## 四、服务启动流程

### 4.1 流程图

```
用户 (Web UI)
    ↓ 1. 点击启动服务
ClusterServiceInstanceController.start()
    ↓ 2. 获取服务信息
    ↓ 3. 检查依赖服务状态
    ↓ 4. 构建启动 DAG
    ↓ 5. 按顺序启动角色
ClusterActor
    ↓ 6. 分发启动命令
DispatcherWorkerActor
    ↓ 7. 发送到 Worker
Worker (StartServiceHandler)
    ├─ 8. 检查服务状态
    ├─ 9. 生成启动命令
    ├─ 10. 执行启动脚本
    └─ 11. 等待服务就绪
    ↓ 12. 返回结果
ServiceExecuteResultActor
    ↓ 13. 更新服务状态
    ↓ 14. 发送通知
Web UI
    ↓ 显示服务状态
```

### 4.2 服务角色启动顺序

以 HDFS 为例：

```java
public List<String> getHdfsStartOrder() {
    List<String> order = new ArrayList<>();
    
    // 1. 首先启动 NameNode (主节点)
    order.add("NameNode");
    
    // 2. 等待 NameNode 启动完成
    // 3. 启动 SecondaryNameNode
    order.add("SecondaryNameNode");
    
    // 4. 启动 DataNode (从节点，可并行)
    order.add("DataNode");
    
    // 5. 启动 JournalNode (如果是 HA 模式)
    order.add("JournalNode");
    
    // 6. 启动 ZKFailoverController (如果是 HA 模式)
    order.add("ZKFailoverController");
    
    return order;
}
```

### 4.3 启动命令生成

```java
public class StartCommandGenerator {
    
    public String generateStartCommand(ServiceRoleInfo roleInfo) {
        String serviceName = roleInfo.getServiceName();
        String roleName = roleInfo.getRoleName();
        
        StringBuilder cmd = new StringBuilder();
        
        // 1. 切换到安装目录
        cmd.append("cd ").append(roleInfo.getInstallPath()).append(" && ");
        
        // 2. 设置环境变量
        cmd.append("export JAVA_HOME=").append(getJavaHome()).append(" && ");
        
        // 3. 根据服务类型生成启动命令
        switch (serviceName) {
            case "HDFS":
                cmd.append(generateHdfsStartCommand(roleName));
                break;
            case "YARN":
                cmd.append(generateYarnStartCommand(roleName));
                break;
            case "KAFKA":
                cmd.append(generateKafkaStartCommand(roleName));
                break;
            // ... 其他服务
        }
        
        return cmd.toString();
    }
    
    private String generateHdfsStartCommand(String roleName) {
        switch (roleName) {
            case "NameNode":
                return "./sbin/hadoop-daemon.sh start namenode";
            case "DataNode":
                return "./sbin/hadoop-daemon.sh start datanode";
            case "SecondaryNameNode":
                return "./sbin/hadoop-daemon.sh start secondarynamenode";
            default:
                throw new IllegalArgumentException("Unknown role: " + roleName);
        }
    }
}
```

### 4.4 服务健康检查

```java
public class ServiceHealthChecker {
    
    public boolean checkServiceHealth(String serviceName, String roleName) {
        try {
            // 1. 检查进程是否存在
            if (!isProcessRunning(serviceName, roleName)) {
                return false;
            }
            
            // 2. 检查端口是否监听
            if (!isPortListening(getServicePort(serviceName, roleName))) {
                return false;
            }
            
            // 3. 检查 HTTP 接口（如果有）
            if (hasHttpInterface(serviceName, roleName)) {
                if (!checkHttpHealth(serviceName, roleName)) {
                    return false;
                }
            }
            
            return true;
        } catch (Exception e) {
            logger.error("Health check failed", e);
            return false;
        }
    }
    
    private boolean checkHttpHealth(String serviceName, String roleName) {
        String url = getHealthCheckUrl(serviceName, roleName);
        try {
            HttpResponse response = HttpUtils.get(url, 5000);
            return response.getStatusCode() == 200;
        } catch (Exception e) {
            return false;
        }
    }
}
```

## 五、配置管理流程

### 5.1 配置下发流程

```
用户 (Web UI)
    ↓ 1. 修改配置
ClusterServiceInstanceConfigController.update()
    ↓ 2. 验证配置
    ↓ 3. 保存到数据库
    ↓ 4. 标记需要重启
    ↓ 5. 下发配置到节点
DispatcherWorkerActor
    ↓ 6. 发送配置更新命令
Worker (ConfigureServiceHandler)
    ├─ 7. 备份旧配置
    ├─ 8. 渲染配置模板
    ├─ 9. 写入配置文件
    └─ 10. 验证配置
    ↓ 11. 返回结果
Master
    ↓ 12. 提示用户重启服务
```

### 5.2 配置模板渲染

```java
public class ConfigTemplateRenderer {
    
    private Configuration freemarkerConfig;
    
    public String renderTemplate(String templateContent, 
                                Map<String, Object> variables) {
        try {
            // 1. 创建模板
            Template template = new Template(
                "config",
                new StringReader(templateContent),
                freemarkerConfig
            );
            
            // 2. 渲染模板
            StringWriter writer = new StringWriter();
            template.process(variables, writer);
            
            return writer.toString();
        } catch (Exception e) {
            throw new RuntimeException("Template rendering failed", e);
        }
    }
}
```

**模板示例 (hdfs-site.xml.ftl)**:
```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>${dfs_replication}</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>${namenode_data_dir}</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>${datanode_data_dir}</value>
    </property>
</configuration>
```

### 5.3 配置版本管理

```java
public class ConfigVersionManager {
    
    public void saveConfigVersion(Integer serviceInstanceId,
                                  String configContent) {
        ConfigHistoryEntity history = new ConfigHistoryEntity();
        history.setServiceInstanceId(serviceInstanceId);
        history.setConfigContent(configContent);
        history.setVersion(getNextVersion(serviceInstanceId));
        history.setCreateTime(new Date());
        
        configHistoryMapper.insert(history);
    }
    
    public String rollbackToVersion(Integer serviceInstanceId, 
                                    Integer version) {
        ConfigHistoryEntity history = configHistoryMapper
            .selectByServiceInstanceIdAndVersion(serviceInstanceId, version);
        
        if (history == null) {
            throw new RuntimeException("Version not found");
        }
        
        return history.getConfigContent();
    }
}
```

## 六、监控告警流程

### 6.1 监控数据采集流程

```
服务进程 (JMX/HTTP)
    ↓ 暴露指标
Prometheus Exporter
    ↓ 格式化指标
Prometheus Server
    ↓ 定期抓取 (默认15s)
TSDB (时序数据库)
    ↓ 存储数据
DataSophon API
    ↓ PromQL 查询
    ↓ 聚合计算
    ↓ 返回数据
Web UI
    ↓ 图表展示
```

### 6.2 告警规则评估

```yaml
# Prometheus 告警规则
groups:
  - name: hdfs_alerts
    rules:
      - alert: NameNodeDown
        expr: up{job="hdfs-namenode"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "NameNode is down"
          description: "NameNode has been down for more than 1 minute"
      
      - alert: DataNodeDiskUsageHigh
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "DataNode disk usage high"
          description: "Disk usage is above 90%"
```

### 6.3 告警处理流程

```
Prometheus
    ↓ 触发告警规则
AlertManager
    ↓ 路由分组
    ↓ 抑制/静默
    ↓ Webhook 通知
DataSophon API
    ↓ 接收告警
    ↓ 保存到数据库
    ↓ 查询告警组
    ↓ 发送通知
告警接收者
    ├─ 邮件
    ├─ 短信
    ├─ 钉钉
    └─ 企业微信
```

## 七、故障恢复流程

### 7.1 Worker 节点故障恢复

```
Master (心跳检测)
    ↓ 检测到 Worker 失联
    ↓ 标记主机为 OFFLINE
    ↓ 标记该主机上的服务为 UNKNOWN
    ↓ 发送告警
    ↓ 等待 Worker 恢复
Worker 恢复
    ↓ 重新注册到 Master
    ↓ 上报本地服务状态
Master
    ↓ 更新主机状态为 ONLINE
    ↓ 更新服务状态
    ↓ 发送恢复通知
```

### 7.2 服务故障恢复

```
监控系统
    ↓ 检测到服务异常
    ↓ 发送告警
Master
    ↓ 尝试自动重启
DispatcherWorkerActor
    ↓ 发送重启命令
Worker
    ├─ 停止服务
    ├─ 清理临时文件
    ├─ 检查配置
    └─ 启动服务
    ↓ 返回结果
Master
    ↓ 更新服务状态
    ↓ 发送通知
```

## 八、总结

DataSophon 的核心业务流程设计精巧，充分利用了 Actor 模型、DAG 图、策略模式等技术，实现了：

1. **高效的任务调度**: 通过 DAG 图和拓扑排序，自动处理服务依赖关系
2. **可靠的分布式执行**: 使用 Actor 模型实现异步、容错的任务执行
3. **灵活的配置管理**: 模板化配置，支持版本管理和回滚
4. **完善的监控告警**: 与 Prometheus 深度集成，实时监控和告警
5. **自动故障恢复**: 心跳检测、自动重启等机制保证服务可用性

---

**文档版本**: v1.0  
**最后更新**: 2025-11-15
